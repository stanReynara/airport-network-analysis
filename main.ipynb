{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airport Network\n",
    "Open-Source Data from https://ourairports.com/data dan https://openflights.org/data.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "import networkx as nx\n",
    "from deap import base, creator, tools, algorithms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from scipy.stats import gaussian_kde\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from matplotlib.colors import Normalize, LinearSegmentedColormap\n",
    "from pyvis.network import Network\n",
    "\n",
    "# Load the CSV file for the airports\n",
    "airports_df = pd.read_csv('airports.csv')\n",
    "\n",
    "airports_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "def on_scroll(event): \n",
    "    # Zoom in or out \n",
    "    base_scale = 1.2 \n",
    "    if event.button == 'up':  # Scroll up \n",
    "        scale_factor = 1 / base_scale \n",
    "    elif event.button == 'down':  # Scroll down \n",
    "        scale_factor = base_scale \n",
    "    else: \n",
    "        return \n",
    " \n",
    "    cur_xlim = ax.get_xlim() \n",
    "    cur_ylim = ax.get_ylim() \n",
    "    xdata = event.xdata  # Get mouse x position \n",
    "    ydata = event.ydata  # Get mouse y position \n",
    " \n",
    "    # Calculate new limits \n",
    "    new_width = (cur_xlim[1] - cur_xlim[0]) * scale_factor \n",
    "    new_height = (cur_ylim[1] - cur_ylim[0]) * scale_factor \n",
    "    relx = (cur_xlim[1] - xdata) / (cur_xlim[1] - cur_xlim[0]) \n",
    "    rely = (cur_ylim[1] - ydata) / (cur_ylim[1] - cur_ylim[0]) \n",
    " \n",
    "    ax.set_xlim([xdata - new_width * (1 - relx), xdata + new_width * relx]) \n",
    "    ax.set_ylim([ydata - new_height * (1 - rely), ydata + new_height * rely]) \n",
    "    ax.figure.canvas.draw() \n",
    " \n",
    "# Connect the event \n",
    "fig.canvas.mpl_connect('scroll_event', on_scroll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file, replacing \"NA\" with \"North America\"\n",
    "df2 = pd.read_csv('airports_big.csv', na_values=[\"NA\"])\n",
    "\n",
    "# Replace \"NA\" with \"North America\" after loading\n",
    "df2.fillna(\"North America\", inplace=True)\n",
    "\n",
    "# Filter the data\n",
    "filtered_df2 = df2[df2['type'].isin(['large_airport', 'medium_airport'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter df where either 'ICAO' or 'IATA' is in filtered_df2['ident']\n",
    "filtered_df = airports_df[\n",
    "    airports_df['ICAO'].isin(filtered_df2['ident']) | airports_df['IATA'].isin(filtered_df2['ident'])\n",
    "]\n",
    "# print(filtered_df2[filtered_df2['name'] == 'Los Angeles International Airport'])\n",
    "\n",
    "# Merge the filtered DataFrame with the continent column from filtered_df2\n",
    "filtered_df = filtered_df.merge(filtered_df2[['ident', 'continent']], left_on='ICAO', right_on='ident', how='left')\n",
    "# print(filtered_df[filtered_df['name'] == 'Los Angeles International Airport'])\n",
    "\n",
    "# Drop the 'ident' column from the merged DataFrame as it's not needed anymore\n",
    "filtered_df = filtered_df.drop(columns=['ident'])\n",
    "\n",
    "# Display the filtered DataFrame with the continent column\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airports are the Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom blue-to-red colormap\n",
    "blue_to_red = LinearSegmentedColormap.from_list('BlueToRed', ['blue', 'lightgray', 'red'])\n",
    "\n",
    "# Create a figure for the globe map\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Set up the Basemap with a Robinson projection for a global view\n",
    "m = Basemap(projection='robin', lon_0=0, resolution='c')  # Center at 0 longitude\n",
    "\n",
    "# Draw map features\n",
    "m.drawcoastlines()\n",
    "m.drawcountries()\n",
    "m.fillcontinents(color='lightgray', lake_color='aqua')\n",
    "m.drawmapboundary(fill_color='aqua')\n",
    "\n",
    "# Convert latitude and longitude to map coordinates\n",
    "x, y = m(filtered_df['lon'].values, filtered_df['lat'].values)\n",
    "\n",
    "# Perform kernel density estimation (KDE) to calculate density\n",
    "positions = np.vstack([x, y])\n",
    "kde = gaussian_kde(positions)\n",
    "density = kde(positions)\n",
    "\n",
    "# Normalize density to enhance visibility\n",
    "norm = Normalize(vmin=np.percentile(density, 5), vmax=density.max())  # Clip lower percentiles\n",
    "density_normalized = norm(density)\n",
    "\n",
    "# Plot the airport locations with the custom colormap\n",
    "sc = m.scatter(x, y, s=5, c=density_normalized, cmap=blue_to_red, marker='o', alpha=1, label='Airports')\n",
    "\n",
    "# Add a colorbar to show density levels\n",
    "# cbar = plt.colorbar(sc, label='Point Density')\n",
    "# cbar.ax.set_ylabel('Point Density', rotation=270, labelpad=15)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend(loc='lower left')\n",
    "\n",
    "# Add a title\n",
    "plt.title(\"Global Airport Locations\")\n",
    "\n",
    "# Show the map\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# These are all used routes (edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "edges = pd.read_csv('routes.csv')\n",
    "\n",
    "# Select only the routes and destination columns (3 and 5)\n",
    "routes = edges[['source_airport_id', 'destination_airport_id']]\n",
    "\n",
    "# This still shows all available routes between airports, heliports and others that are not accessible by the average person, so we need to filter it again\n",
    "routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(routes['source_airport_id'].dtype) \n",
    "print(routes['destination_airport_id'].dtype)\n",
    "\n",
    "# Convert both 'source_airport_id' and 'destination_airport_id' to numeric, forcing non-numeric values to NaN\n",
    "routes['source_airport_id'] = pd.to_numeric(routes['source_airport_id'], errors='coerce')\n",
    "routes['destination_airport_id'] = pd.to_numeric(routes['destination_airport_id'], errors='coerce')\n",
    "\n",
    "# Drop rows where either 'source_airport_id' or 'destination_airport_id' is NaN\n",
    "routes = routes.dropna(subset=['source_airport_id', 'destination_airport_id'])\n",
    "\n",
    "# Convert both columns to int64\n",
    "routes['source_airport_id'] = routes['source_airport_id'].astype('int64')\n",
    "routes['destination_airport_id'] = routes['destination_airport_id'].astype('int64')\n",
    "\n",
    "# Verify the data types\n",
    "print(routes[['source_airport_id', 'destination_airport_id']].dtypes)\n",
    "\n",
    "routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_routes = routes[\n",
    "    routes['source_airport_id'].isin(filtered_df['id']) & \n",
    "    routes['destination_airport_id'].isin(filtered_df['id'])\n",
    "]\n",
    "# Create a 'reverse' pair column to track the reverse direction\n",
    "available_routes['reverse_pair'] = list(zip(available_routes['destination_airport_id'], available_routes['source_airport_id']))\n",
    "\n",
    "# Remove duplicates, including reverse pairs\n",
    "unique_routes = []\n",
    "seen_routes = set()\n",
    "\n",
    "for index, row in available_routes.iterrows():\n",
    "    pair = (row['source_airport_id'], row['destination_airport_id'])\n",
    "    reverse_pair = (row['destination_airport_id'], row['source_airport_id'])\n",
    "\n",
    "    # If neither the pair nor the reverse pair has been seen before, add it to the unique_routes list\n",
    "    if pair not in seen_routes and reverse_pair not in seen_routes:\n",
    "        unique_routes.append(row)\n",
    "        seen_routes.add(pair)\n",
    "\n",
    "# Convert the list back into a DataFrame\n",
    "available_routes = pd.DataFrame(unique_routes)\n",
    "\n",
    "# Drop the 'reverse_pair' column\n",
    "available_routes = available_routes.drop(columns=['reverse_pair'])\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(available_routes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a unique number to each continent code in the 'continent' column\n",
    "labels, uniques = pd.factorize(filtered_df['continent'])\n",
    "filtered_df['continent'] = labels + 1  # Assign unique numbers starting from 1\n",
    "\n",
    "# Create a mapping dictionary\n",
    "continent_mapping = {index + 1: value for index, value in enumerate(uniques)}\n",
    "\n",
    "# Display the mapping\n",
    "print(continent_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the updated DataFrame\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes from the 'id' column of filtered_df\n",
    "# G.add_nodes_from(filtered_df['id'], group=row[\"continent\"])\n",
    "\n",
    "for index, row in filtered_df.iterrows():\n",
    "    G.add_node(row[\"id\"], group=row[\"continent\"], name=row[\"name\"])\n",
    "\n",
    "# Add edges\n",
    "edges = list(zip(available_routes['source_airport_id'], available_routes['destination_airport_id']))\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "# Display basic information about the graph\n",
    "print(f\"Number of nodes: {G.number_of_nodes()}\")\n",
    "print(f\"Number of edges: {G.number_of_edges()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.is_connected(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.number_connected_components(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draws graph for all airports locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the drawing function\n",
    "def draw_graph(G, size, withLabelsBool):\n",
    "    # Remove nodes with 0 degree\n",
    "    G = G.copy()  # Work on a copy to avoid modifying the original graph\n",
    "    nodes_to_remove = [n for n, degree in G.degree() if degree == 0]\n",
    "    G.remove_nodes_from(nodes_to_remove)\n",
    "    \n",
    "    # Define a color map\n",
    "    color_map = {1: '#f09494', 2: '#eebcbc', 3: '#72bbd0', 4: '#91f0a1', 5: '#629fff', 6: '#bcc2f2', 7: '#eebcbc'}\n",
    "    \n",
    "    # Assign colors to nodes based on their 'group' attribute\n",
    "    node_color = []\n",
    "    for n, d in G.nodes(data=True):\n",
    "        group = d.get('group', None)  # Get 'group' attribute safely\n",
    "        if group in color_map:\n",
    "            node_color.append(color_map[group])\n",
    "        else:\n",
    "            node_color.append('#fff')  # Default color for missing or unexpected group values\n",
    "    \n",
    "    # Layout for nodes\n",
    "    pos = nx.drawing.kamada_kawai_layout(G)\n",
    "    # pos = nx.spring_layout(G)\n",
    "    \n",
    "    # Extract node labels (e.g., airport names)\n",
    "    labels = {n: d['name'] for n, d in G.nodes(data=True)}\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=size)\n",
    "    nx.draw_networkx(G, pos=pos, node_color=node_color, edge_color='#FFDEA2', with_labels=withLabelsBool, labels=labels, font_size=8)\n",
    "    # nx.draw_networkx(G, pos=pos, node_color=node_color, edge_color='#FFDEA2', with_labels=not withLabelsBool)\n",
    "    plt.show()\n",
    "\n",
    "# Call the drawing function with the desired figure size\n",
    "draw_graph(G, (25, 25), withLabelsBool=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subgraph for each continents\n",
    "\n",
    "## Oceanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{1: 'OC', 2: 'North America', 3: 'EU', 4: 'AF', 5: 'SA', 6: 'AS', 7: 'AN'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the drawing function\n",
    "def draw_graph_oc(G, size):\n",
    "    # Define a color map\n",
    "    color_map = {1: '#f09494', 2: '#eebcbc', 3: '#72bbd0', 4: '#91f0a1', 5: '#629fff', 6: '#bcc2f2', 7: '#eebcbc'}\n",
    "    \n",
    "    # Filter the graph to include only nodes where 'group' == 2\n",
    "    nodes_group_2 = [n for n, d in G.nodes(data=True) if d.get('group') == 1]\n",
    "    \n",
    "    # Create a subgraph with only these nodes\n",
    "    subgraph = G.subgraph(nodes_group_2)\n",
    "    \n",
    "    # Assign colors to nodes based on their 'group' attribute (just for the subgraph)\n",
    "    node_color = []\n",
    "    for n, d in subgraph.nodes(data=True):\n",
    "        group = d.get('group', None)  # Get 'group' attribute safely\n",
    "        if group in color_map:\n",
    "            node_color.append(color_map[group])\n",
    "        else:\n",
    "            node_color.append('#fff')  # Default color for missing or unexpected group values\n",
    "    \n",
    "    # Layout for nodes\n",
    "    pos = nx.drawing.kamada_kawai_layout(subgraph)\n",
    "    \n",
    "    # Extract node labels (airport names)\n",
    "    labels = {n: d['name'] for n, d in subgraph.nodes(data=True)}\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=size)\n",
    "    nx.draw_networkx(subgraph, pos=pos, node_color=node_color, edge_color='#FFDEA2', labels=labels, font_size=8)\n",
    "    plt.show()\n",
    "\n",
    "# Call the drawing function with the desired figure size\n",
    "draw_graph_oc(G, (30, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## North America"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the drawing function\n",
    "def draw_graph_na(G, size):\n",
    "    # Define a color map\n",
    "    color_map = {1: '#f09494', 2: '#eebcbc', 3: '#72bbd0', 4: '#91f0a1', 5: '#629fff', 6: '#bcc2f2', 7: '#eebcbc'}\n",
    "    \n",
    "    # Filter the graph to include only nodes where 'group' == 2\n",
    "    nodes_group_2 = [n for n, d in G.nodes(data=True) if d.get('group') == 2]\n",
    "    \n",
    "    # Create a subgraph with only these nodes\n",
    "    subgraph = G.subgraph(nodes_group_2)\n",
    "    \n",
    "    # Assign colors to nodes based on their 'group' attribute (just for the subgraph)\n",
    "    node_color = []\n",
    "    for n, d in subgraph.nodes(data=True):\n",
    "        group = d.get('group', None)  # Get 'group' attribute safely\n",
    "        if group in color_map:\n",
    "            node_color.append(color_map[group])\n",
    "        else:\n",
    "            node_color.append('#fff')  # Default color for missing or unexpected group values\n",
    "    \n",
    "    # Layout for nodes\n",
    "    pos = nx.drawing.kamada_kawai_layout(subgraph)\n",
    "    \n",
    "    # Extract node labels (airport names)\n",
    "    labels = {n: d['name'] for n, d in subgraph.nodes(data=True)}\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=size)\n",
    "    nx.draw_networkx(subgraph, pos=pos, node_color=node_color, edge_color='#FFDEA2', labels=labels, font_size=8)\n",
    "    plt.show()\n",
    "\n",
    "# Call the drawing function with the desired figure size\n",
    "draw_graph_na(G, (30, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the drawing function\n",
    "def draw_graph_eu(G, size):\n",
    "    # Define a color map\n",
    "    color_map = {1: '#f09494', 2: '#eebcbc', 3: '#72bbd0', 4: '#91f0a1', 5: '#629fff', 6: '#bcc2f2', 7: '#eebcbc'}\n",
    "    \n",
    "    # Filter the graph to include only nodes where 'group' == 2\n",
    "    nodes_group_3 = [n for n, d in G.nodes(data=True) if d.get('group') == 3]\n",
    "    \n",
    "    # Create a subgraph with only these nodes\n",
    "    subgraph = G.subgraph(nodes_group_3)\n",
    "    \n",
    "    # Assign colors to nodes based on their 'group' attribute (just for the subgraph)\n",
    "    node_color = []\n",
    "    for n, d in subgraph.nodes(data=True):\n",
    "        group = d.get('group', None)  # Get 'group' attribute safely\n",
    "        if group in color_map:\n",
    "            node_color.append(color_map[group])\n",
    "        else:\n",
    "            node_color.append('#fff')  # Default color for missing or unexpected group values\n",
    "    \n",
    "    # Layout for nodes\n",
    "    pos = nx.drawing.kamada_kawai_layout(subgraph)\n",
    "    \n",
    "    # Extract node labels (airport names)\n",
    "    labels = {n: d['name'] for n, d in subgraph.nodes(data=True)}\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=size)\n",
    "    nx.draw_networkx(subgraph, pos=pos, node_color=node_color, edge_color='#FFDEA2', labels=labels, font_size=8)\n",
    "    plt.show()\n",
    "\n",
    "# Call the drawing function with the desired figure size\n",
    "draw_graph_eu(G, (30, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pyvis network\n",
    "net = Network(notebook=True, height=\"800px\", width=\"100%\")\n",
    "\n",
    "# Add nodes and edges from NetworkX graph\n",
    "net.from_nx(G)\n",
    "\n",
    "# Customize appearance (optional)\n",
    "net.force_atlas_2based()  # Force-directed layout\n",
    "\n",
    "# Show the network\n",
    "net.show(\"graph.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from community import community_louvain\n",
    "\n",
    "partition = community_louvain.best_partition(G)\n",
    "\n",
    "num_communities = len(set(partition.values()))\n",
    "print(f\"Number of communities: {num_communities}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subgraph Biggest Community "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to find the largest community and display it with labels as 'name'\n",
    "def display_largest_community(G, size=(25, 25), withLabelsBool=True):\n",
    "    # Compute communities using the Louvain method\n",
    "    partition = community_louvain.best_partition(G)\n",
    "    \n",
    "    # Group nodes by community\n",
    "    community_groups = {}\n",
    "    for node, community_id in partition.items():\n",
    "        if community_id not in community_groups:\n",
    "            community_groups[community_id] = []\n",
    "        community_groups[community_id].append(node)\n",
    "    \n",
    "    # Find the largest community\n",
    "    largest_community_id = max(community_groups, key=lambda k: len(community_groups[k]))\n",
    "    largest_community_nodes = community_groups[largest_community_id]\n",
    "    \n",
    "    # Extract the subgraph of the largest community\n",
    "    largest_community_subgraph = G.subgraph(largest_community_nodes)\n",
    "    \n",
    "    # Extract node labels (based on 'name' attribute)\n",
    "    labels = {n: G.nodes[n].get('name', str(n)) for n in largest_community_nodes}\n",
    "    \n",
    "    # Draw the largest community subgraph\n",
    "    pos = nx.spring_layout(largest_community_subgraph)  # Layout for the largest community\n",
    "    plt.figure(figsize=size)\n",
    "    nx.draw(\n",
    "        largest_community_subgraph,\n",
    "        pos,\n",
    "        with_labels=withLabelsBool,\n",
    "        labels=labels,\n",
    "        node_color='#72bbd0',\n",
    "        edge_color='#FFDEA2',\n",
    "        font_size=10,\n",
    "        node_size=500,\n",
    "    )\n",
    "    plt.title(f\"Largest Community (Size: {len(largest_community_nodes)})\")\n",
    "    plt.show()\n",
    "\n",
    "display_largest_community(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the degree of each node in the graph\n",
    "degrees = [G.degree(n) for n in G.nodes()]\n",
    "\n",
    "# Calculate the average degree\n",
    "average_degree = np.mean(degrees)\n",
    "print(f\"Average degree: {average_degree}\")\n",
    "\n",
    "# Degree distribution: Frequency of each degree\n",
    "degree_count = {}\n",
    "for degree in degrees:\n",
    "    if degree not in degree_count:\n",
    "        degree_count[degree] = 1\n",
    "    else:\n",
    "        degree_count[degree] += 1\n",
    "\n",
    "# Print the degree distribution\n",
    "print(\"Degree Distribution:\")\n",
    "for degree, count in sorted(degree_count.items()):\n",
    "    print(f\"Degree {degree}: {count} nodes\")\n",
    "\n",
    "# Plotting the degree distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(degree_count.keys(), degree_count.values(), color='#72bbd0')\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('Number of nodes')\n",
    "plt.title('Degree Distribution of the Graph')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we remove the empty nodes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nodes with degree 0\n",
    "nodes_to_remove = [n for n in G.nodes() if G.degree(n) == 0]\n",
    "G.remove_nodes_from(nodes_to_remove)\n",
    "\n",
    "# Recalculate degrees after removing nodes\n",
    "degrees = [G.degree(n) for n in G.nodes()]\n",
    "\n",
    "# Recalculate average degree\n",
    "average_degree = np.mean(degrees)\n",
    "print(f\"Average degree after removing nodes with degree 0: {average_degree}\")\n",
    "\n",
    "# Recalculate degree distribution\n",
    "degree_count = {}\n",
    "for degree in degrees:\n",
    "    if degree not in degree_count:\n",
    "        degree_count[degree] = 1\n",
    "    else:\n",
    "        degree_count[degree] += 1\n",
    "\n",
    "# Print the degree distribution\n",
    "print(\"Degree Distribution after removing nodes with degree 0:\")\n",
    "for degree, count in sorted(degree_count.items()):\n",
    "    print(f\"Degree {degree}: {count} nodes\")\n",
    "\n",
    "# Plot the updated degree distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(degree_count.keys(), degree_count.values(), color='#72bbd0')\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('Number of nodes')\n",
    "plt.title('Updated Degree Distribution of the Graph')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max Degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the airport (node) with the highest degree\n",
    "max_degree_node = max(G.degree, key=lambda x: x[1])  # (node, degree) pair, sorting by degree\n",
    "max_degree_airport_id = max_degree_node[0]  # The airport's ID with the highest degree\n",
    "max_degree = max_degree_node[1]  # The highest degree value\n",
    "\n",
    "# Find the corresponding airport name using the 'name' attribute\n",
    "airport_name = G.nodes[max_degree_airport_id]['name']\n",
    "\n",
    "print(f\"The airport with the most connections (highest degree) is: {airport_name} with {max_degree} connections.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subgraph of Amsterdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the drawing function\n",
    "def draw_graph(G, size, withLabelsBool, center_name=None):\n",
    "    # Remove nodes with 0 degree\n",
    "    G = G.copy()  # Work on a copy to avoid modifying the original graph\n",
    "    nodes_to_remove = [n for n, degree in G.degree() if degree == 0]\n",
    "    G.remove_nodes_from(nodes_to_remove)\n",
    "    \n",
    "    # Define a color map\n",
    "    color_map = {1: '#f09494', 2: '#eebcbc', 3: '#72bbd0', 4: '#91f0a1', 5: '#629fff', 6: '#bcc2f2', 7: '#eebcbc'}\n",
    "    \n",
    "    # Assign colors to nodes based on their 'group' attribute\n",
    "    node_color = []\n",
    "    for n, d in G.nodes(data=True):\n",
    "        group = d.get('group', None)  # Get 'group' attribute safely\n",
    "        if group in color_map:\n",
    "            node_color.append(color_map[group])\n",
    "        else:\n",
    "            node_color.append('#fff')  # Default color for missing or unexpected group values\n",
    "    \n",
    "    # Find the node corresponding to the center name\n",
    "    if center_name:\n",
    "        center_node = None\n",
    "        for n, d in G.nodes(data=True):\n",
    "            if d.get('name') == center_name:\n",
    "                center_node = n\n",
    "                break\n",
    "        if center_node:\n",
    "            # Arrange the layout with the center node in the middle\n",
    "            neighbors = list(G.neighbors(center_node))\n",
    "            pos = {center_node: (0, 0)}  # Place the center node at (0, 0)\n",
    "            \n",
    "            # Arrange neighbors in a circle around the center\n",
    "            num_neighbors = len(neighbors)\n",
    "            for i, neighbor in enumerate(neighbors):\n",
    "                angle = 2 * 3.14159 * i / num_neighbors  # Divide evenly around a circle\n",
    "                pos[neighbor] = (1.5 * np.cos(angle), 1.5 * np.sin(angle))\n",
    "            \n",
    "            # Place other nodes randomly around\n",
    "            for n in G.nodes():\n",
    "                if n not in pos:\n",
    "                    pos[n] = nx.drawing.spring_layout(G, center=center_node)[n]\n",
    "        else:\n",
    "            pos = nx.drawing.spring_layout(G)  # Fallback layout\n",
    "    else:\n",
    "        pos = nx.drawing.spring_layout(G)  # Default layout if no center name is given\n",
    "    \n",
    "    # Extract node labels (e.g., airport names)\n",
    "    labels = {n: d['name'] for n, d in G.nodes(data=True)}\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=size)\n",
    "    nx.draw_networkx(G, pos=pos, node_color=node_color, edge_color='#FFDEA2', with_labels=withLabelsBool, labels=labels, font_size=8)\n",
    "    plt.show()\n",
    "\n",
    "# Filter the graph for the node with a specific name and its neighbors\n",
    "def filter_graph_by_name(G, target_name):\n",
    "    # Find the node with the specified name\n",
    "    target_node = None\n",
    "    for n, d in G.nodes(data=True):\n",
    "        if d.get('name') == target_name:\n",
    "            target_node = n\n",
    "            break\n",
    "    \n",
    "    if target_node is None:\n",
    "        print(f\"No node with the name '{target_name}' found.\")\n",
    "        return nx.Graph()  # Return an empty graph if not found\n",
    "    \n",
    "    # Get the subgraph induced by the target node and its neighbors\n",
    "    nodes_to_include = [target_node] + list(G.neighbors(target_node))\n",
    "    return G.subgraph(nodes_to_include)\n",
    "\n",
    "# Filter the graph for a specific airport\n",
    "filtered_graph = filter_graph_by_name(G, \"Amsterdam Airport Schiphol\")\n",
    "\n",
    "# Draw the filtered graph with the center node\n",
    "draw_graph(filtered_graph, size=(50, 50), withLabelsBool=True, center_name=\"Amsterdam Airport Schiphol\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Coefficient\n",
    "### Menunjukkan bahwa sekitar 1/4 node bersebelahan memiliki tetangga yang juga berhubungan satu sama lain (segitiga) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the global clustering coefficient\n",
    "global_clustering = nx.transitivity(G)\n",
    "print(f\"Global Clustering Coefficient: {global_clustering}\")\n",
    "\n",
    "# Calculate the average local clustering coefficient\n",
    "average_local_clustering = nx.average_clustering(G)\n",
    "print(f\"Average Local Clustering Coefficient: {average_local_clustering}\")\n",
    "\n",
    "# Alternatively, calculate individual clustering coefficients for each node\n",
    "# node_clustering = nx.clustering(G)\n",
    "# print(\"Node Clustering Coefficients:\")\n",
    "# for node, clustering in node_clustering.items():\n",
    "#     print(f\"Node {node} (Airport: {G.nodes[node]['name']}): {clustering}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diameter & Path terpanjang\n",
    "### Menunjukkan bahwa connecting path paling panjang adalah 10 bandara\n",
    "### Rata-rata memerlukan 3-4 \"trip\" untuk sampai ke tujuan akhir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the largest connected component\n",
    "largest_cc = max(nx.connected_components(G), key=len)\n",
    "G_largest_cc = G.subgraph(largest_cc).copy()\n",
    "\n",
    "# Calculate diameter and average path length for the largest connected component\n",
    "if nx.is_connected(G_largest_cc):\n",
    "    diameter = nx.diameter(G_largest_cc)\n",
    "    avg_path_length = nx.average_shortest_path_length(G_largest_cc)\n",
    "    print(f\"Diameter of the largest connected component: {diameter}\")\n",
    "    print(f\"Average Path Length of the largest connected component: {avg_path_length}\")\n",
    "else:\n",
    "    print(\"The largest connected component is still disconnected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling Exponent\n",
    "### Menunjukkan bahwa banyak nodes yang merupakan hubs sedikit dan mayoritas node memiliki degree yang kecil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import powerlaw\n",
    "# Get the degree distribution of the graph\n",
    "degree_sequence = [degree for node, degree in G.degree()]\n",
    "\n",
    "# Fit the degree distribution to a power law using the powerlaw library\n",
    "results = powerlaw.Fit(degree_sequence, xmin=1)  # xmin is the minimum degree considered\n",
    "scaling_exponent = results.alpha  # The scaling exponent (gamma)\n",
    "\n",
    "# Print the scaling exponent\n",
    "print(f\"Scaling Exponent (alpha): {scaling_exponent}\")\n",
    "\n",
    "# Optional: Plot the degree distribution and the fitted power law\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(degree_sequence, bins=range(1, max(degree_sequence)+1), alpha=0.6, color='b', label='Degree Distribution', density=True)\n",
    "plt.plot(range(1, max(degree_sequence)+1), results.power_law.pdf(range(1, max(degree_sequence)+1)), color='r', label=f\"Fitted Power Law (alpha = {scaling_exponent:.2f})\")\n",
    "\n",
    "plt.xscale('log')  # Set x-axis to logarithmic scale\n",
    "plt.yscale('log')  # Set y-axis to logarithmic scale\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('Probability')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assortavity\n",
    "\n",
    "### Assortivity yang negatif menunjukkan bahwa node yang memiliki degree tinggi berkoneksi ke node yang memiliki degree rendah\n",
    "\n",
    "Dalam kasus ini, assortivity dekat dengan 0 sehingga kebanyakan airport berhubungan dengan airport lain yang memiliki degree yang sama/lebih banyak "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the assortativity based on degree\n",
    "assortativity = nx.degree_assortativity_coefficient(G)\n",
    "\n",
    "print(f\"Assortativity coefficient of the graph: {assortativity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modularity\n",
    "\n",
    "### Terdapat grup dan komunitas yang sangat \"dense\" koneksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import community  # You may need to install python-louvain package: pip install python-louvain\n",
    "\n",
    "# Detect communities using the Louvain method\n",
    "partition = community.best_partition(G)\n",
    "\n",
    "# Calculate the modularity of the graph given the partition\n",
    "modularity = community.modularity(partition, G)\n",
    "\n",
    "print(f\"Modularity of the graph: {modularity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Degree Centrality\n",
    "### 580 adalah airport Amsterdam\n",
    "Memiliki paling banyak koneksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate degree centrality for the graph G\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "\n",
    "# Sort the degree centrality values to display the top 10 airports with the highest centrality\n",
    "top_degree_centrality = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "# Prepare results for display\n",
    "print(top_degree_centrality)\n",
    "\n",
    "# Average Centrality\n",
    "average_centrality = sum(degree_centrality.values()) / len(degree_centrality)\n",
    "\n",
    "print(f\"Average centrality: {average_centrality}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Betweenness Centrality\n",
    "### 1382 adalah Charles de Gaulle International Airport di Perancis\n",
    "Penting menjadi \"bridge\", mengkoneksikan node paling banyak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate betweenness centrality\n",
    "betweenness_centrality = nx.betweenness_centrality(G, normalized=True)\n",
    "\n",
    "# Sort the betweenness centrality values to display the top 10 airports with the highest centrality\n",
    "top_betweenness_centrality = sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "# Display the results\n",
    "top_betweenness_centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Closeness Centrality\n",
    "### 340 adalah Frankfurt am Main Airport di Jerman\n",
    "\"Paling tengah\", dekat(sedikit trip) dengan banyak airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate closeness centrality\n",
    "closeness_centrality = nx.closeness_centrality(G)\n",
    "\n",
    "# Sort the closeness centrality values to display the top 10 airports with the highest centrality\n",
    "top_closeness_centrality = sorted(closeness_centrality.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "# Display the results\n",
    "top_closeness_centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EigenVector Centrality\n",
    "### Amsterdam dan Perancis\n",
    "Berhubungan dengan airport yang juga merupakan \"hub\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate eigenvector centrality\n",
    "eigenvector_centrality = nx.eigenvector_centrality(G)\n",
    "\n",
    "# Sort the eigenvector centrality values to display the top 10 airports with the highest centrality\n",
    "top_eigenvector_centrality = sorted(eigenvector_centrality.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "# Display the results\n",
    "top_eigenvector_centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PageRank Centrality\n",
    "### 3682 adalah Hartsfield Jackson Atlanta International Airport di US\n",
    "Jika berhubungan dengan airport populer, nilai PageRank naik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate PageRank\n",
    "pagerank = nx.pagerank(G)\n",
    "\n",
    "# Sort the PageRank values to display the top 10 airports with the highest centrality\n",
    "top_pagerank = sorted(pagerank.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "# Display the results\n",
    "top_pagerank"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_name",
   "language": "python",
   "name": "venv_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
